{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Six Degrees of Kevin Bacon\n",
    "\n",
    "![](images/Kevin_Bacon.jpg)\n",
    "\n",
    "This activity is motivated by the text **Web Scraping with Python** by Ryan Mitchell, available through O'Reilly [here](http://shop.oreilly.com/product/0636920078067.do).  This book goes in depth with much more on using different libraries with Python around common webscraping tasks and I highly recommend it.  We will focus on the activity of moving from a base page to further pages through their links.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Links\n",
    "\n",
    "Below, we take the page dealing with the six degrees of Keving Bacon problem.  Here, our goal is to extract links to other pages that we will subsequently pass to requests.  Recall that a link is located in an `<a>` tag and the link is contained in the `href` attribute.  For example, the tag\n",
    "\n",
    "```HTML\n",
    "<a href=\"/wiki/Six_degrees_of_separation\" title=\"Six degrees of separation\">six degrees of separation</a>\n",
    "```\n",
    "\n",
    "references the Six Degrees of Separation article.  Note that this is a url within Wikipedia.  We can isolate these inner Wikipedia references.  To begin, let's inspect the link content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a id=\"top\"></a>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a id=\"top\"></a>,\n",
       " <a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>,\n",
       " <a class=\"mw-jump-link\" href=\"#p-search\">Jump to search</a>,\n",
       " <a class=\"image\" href=\"/wiki/File:Kevin_Bacon.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"461\" data-file-width=\"369\" height=\"275\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Kevin_Bacon.jpg/220px-Kevin_Bacon.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Kevin_Bacon.jpg/330px-Kevin_Bacon.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/d/d2/Kevin_Bacon.jpg 2x\" width=\"220\"/></a>,\n",
       " <a class=\"internal\" href=\"/wiki/File:Kevin_Bacon.jpg\" title=\"Enlarge\"></a>,\n",
       " <a class=\"mw-redirect\" href=\"/wiki/Parlor_game\" title=\"Parlor game\">parlor game</a>,\n",
       " <a href=\"/wiki/Six_degrees_of_separation\" title=\"Six degrees of separation\">six degrees of separation</a>,\n",
       " <a href=\"/wiki/Kevin_Bacon\" title=\"Kevin Bacon\">Kevin Bacon</a>,\n",
       " <a href=\"/wiki/Hollywood\" title=\"Hollywood\">Hollywood</a>,\n",
       " <a href=\"/wiki/Kevin_Bacon\" title=\"Kevin Bacon\">Bacon</a>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'top'}\n",
      "{'class': ['mw-jump-link'], 'href': '#mw-head'}\n",
      "{'class': ['mw-jump-link'], 'href': '#p-search'}\n",
      "{'href': '/wiki/File:Kevin_Bacon.jpg', 'class': ['image']}\n",
      "{'href': '/wiki/File:Kevin_Bacon.jpg', 'class': ['internal'], 'title': 'Enlarge'}\n",
      "{'href': '/wiki/Parlor_game', 'class': ['mw-redirect'], 'title': 'Parlor game'}\n",
      "{'href': '/wiki/Six_degrees_of_separation', 'title': 'Six degrees of separation'}\n",
      "{'href': '/wiki/Kevin_Bacon', 'title': 'Kevin Bacon'}\n",
      "{'href': '/wiki/Hollywood', 'title': 'Hollywood'}\n",
      "{'href': '/wiki/Kevin_Bacon', 'title': 'Kevin Bacon'}\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a')[:10]:\n",
    "    print(link.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#mw-head\n",
      "#p-search\n",
      "/wiki/File:Kevin_Bacon.jpg\n",
      "/wiki/File:Kevin_Bacon.jpg\n",
      "/wiki/Parlor_game\n",
      "/wiki/Six_degrees_of_separation\n",
      "/wiki/Kevin_Bacon\n",
      "/wiki/Hollywood\n",
      "/wiki/Kevin_Bacon\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a')[:10]:\n",
    "    if 'href' in link.attrs:\n",
    "        print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, seems there are links outside of the inner wiki links.  However, we see that the wiki links contain `/wiki/`, no colons, and the links are all within the body of the page.  Exploiting these means we can write a regular expression \n",
    "\n",
    "```\n",
    "^(/wiki/)((?!:).)*$\n",
    "```\n",
    "\n",
    "that will match only the wiki links.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('a')[:10]:\n",
    "    linkers = re.compile('^(/wiki/)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'^(/wiki/)', re.UNICODE)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/wiki/Parlor_game\n",
      "/wiki/Six_degrees_of_separation\n",
      "/wiki/Kevin_Bacon\n",
      "/wiki/Hollywood\n",
      "/wiki/Kevin_Bacon\n",
      "/wiki/Kevin_Bacon\n",
      "/wiki/Charitable_organization\n",
      "/wiki/SixDegrees.org\n",
      "/wiki/Premiere_(magazine)\n",
      "/wiki/Kevin_Bacon\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find('div', {'id': 'bodyContent'}).find_all('a', href = re.compile('^(/wiki/)((?!:).)*$'))[:10]:\n",
    "    if 'href' in link.attrs:\n",
    "        print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Function for Links\n",
    "\n",
    "Now, let's write a function that extracts the link from any wikipedia page.  We should be able to use the idea that the links we care about are located in the same place as our Six Degrees example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikilinks(url):\n",
    "    links = []\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for link in soup.find('div', {'id': 'bodyContent'}).find_all('a', href = re.compile('^(/wiki/)((?!:).)*$')):\n",
    "        links.append(link)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = get_wikilinks('https://en.wikipedia.org/wiki/Kevin_Bacon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"mw-disambig\" href=\"/wiki/Kevin_Bacon_(disambiguation)\" title=\"Kevin Bacon (disambiguation)\">Kevin Bacon (disambiguation)</a>,\n",
       " <a href=\"/wiki/Philadelphia\" title=\"Philadelphia\">Philadelphia</a>,\n",
       " <a href=\"/wiki/Pennsylvania\" title=\"Pennsylvania\">Pennsylvania</a>,\n",
       " <a href=\"/wiki/Kyra_Sedgwick\" title=\"Kyra Sedgwick\">Kyra Sedgwick</a>,\n",
       " <a href=\"/wiki/Sosie_Bacon\" title=\"Sosie Bacon\">Sosie Bacon</a>,\n",
       " <a href=\"/wiki/Edmund_Bacon_(architect)\" title=\"Edmund Bacon (architect)\">Edmund Bacon</a>,\n",
       " <a href=\"/wiki/Michael_Bacon_(musician)\" title=\"Michael Bacon (musician)\">Michael Bacon</a>,\n",
       " <a href=\"/wiki/Footloose_(1984_film)\" title=\"Footloose (1984 film)\">Footloose</a>,\n",
       " <a href=\"/wiki/JFK_(film)\" title=\"JFK (film)\">JFK</a>,\n",
       " <a href=\"/wiki/A_Few_Good_Men\" title=\"A Few Good Men\">A Few Good Men</a>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "for i in links[:10]:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Pages\n",
    "\n",
    "Now, we want to follow these references, gather more urls, and repeat. For the sake of not running to exhaustion, I abbreviate the output using only a large length requirement for the link list.  To traverse all the pages we would simply change the \n",
    "\n",
    "```python\n",
    "while len(links) > 100:\n",
    "```\n",
    "\n",
    "to \n",
    "\n",
    "```python\n",
    "while len(links) > 0:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_wikilinks(url):\n",
    "    links = []\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for link in soup.find('div', {'id': 'bodyContent'}).find_all('a', href = re.compile('^(/wiki/)((?!:).)*$')):\n",
    "        links.append(link)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/I_Love_Dick_(TV_series)\n",
      "https://en.wikipedia.org/wiki/Ripper_Street\n",
      "https://en.wikipedia.org/wiki/Arrested_Development_(TV_series)\n",
      "https://en.wikipedia.org/wiki/The_Last_Kingdom_(TV_series)\n",
      "https://en.wikipedia.org/wiki/Matthew_MacFadyen\n",
      "https://en.wikipedia.org/wiki/BBC_Radio_4\n",
      "https://en.wikipedia.org/wiki/CBS_Drama\n",
      "https://en.wikipedia.org/wiki/KPIX-TV\n",
      "https://en.wikipedia.org/wiki/1964_Chicago_Cubs_season\n",
      "https://en.wikipedia.org/wiki/WGN-TV\n",
      "https://en.wikipedia.org/wiki/Ryne_Sandberg#\"The_Sandberg_Game\"\n",
      "https://en.wikipedia.org/wiki/Rob_Neyer\n"
     ]
    }
   ],
   "source": [
    "links = get_wikilinks('https://en.wikipedia.org/wiki/Kevin_Bacon')\n",
    "while len(links) > 100:\n",
    "    newArticle = 'https://en.wikipedia.org' + links[random.randint(0, len(links)-1)].attrs['href']\n",
    "    print(newArticle)\n",
    "    links = get_wikilinks(newArticle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "Write a function to retrieve a list of albums of any area you are interested in using Wikipedia's list of list of albums page: https://en.wikipedia.org/wiki/Lists_of_albums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://en.wikipedia.org/wiki/Walt_Disney_Records_discography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"wikitable\">\n",
       "<tbody><tr>\n",
       "<th>Year</th>\n",
       "<th>Soundtrack</th>\n",
       "<th>Original release</th>\n",
       "<th>Reissue\n",
       "</th></tr>\n",
       "<tr>\n",
       "<td>1937</td>\n",
       "<td><i><a href=\"/wiki/Snow_White_and_the_Seven_Dwarfs_(soundtrack)\" title=\"Snow White and the Seven Dwarfs (soundtrack)\">Snow White and the Seven Dwarfs</a></i></td>\n",
       "<td>January 1938 (three 78rpm singles) <a class=\"mw-redirect\" href=\"/wiki/Victor_Records\" title=\"Victor Records\">Victor Records</a></td>\n",
       "<td>June 8, 1993 (CD)<br/>September 25, 2001 (CD) (Remastered)\n",
       "</td></tr>\n",
       "</tbody></table>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"wikitable\">\n",
       "<tbody><tr>\n",
       "<th>Year</th>\n",
       "<th>Soundtrack</th>\n",
       "<th>Original release</th>\n",
       "<th>Reissue\n",
       "</th></tr>\n",
       "<tr>\n",
       "<td>1937</td>\n",
       "<td><i><a href=\"/wiki/Snow_White_and_the_Seven_Dwarfs_(soundtrack)\" title=\"Snow White and the Seven Dwarfs (soundtrack)\">Snow White and the Seven Dwarfs</a></i></td>\n",
       "<td>January 1938 (three 78rpm singles) <a class=\"mw-redirect\" href=\"/wiki/Victor_Records\" title=\"Victor Records\">Victor Records</a></td>\n",
       "<td>June 8, 1993 (CD)<br/>September 25, 2001 (CD) (Remastered)\n",
       "</td></tr>\n",
       "</tbody></table>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>1937</td>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].find('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td>1937</td>,\n",
       " <td><i><a href=\"/wiki/Snow_White_and_the_Seven_Dwarfs_(soundtrack)\" title=\"Snow White and the Seven Dwarfs (soundtrack)\">Snow White and the Seven Dwarfs</a></i></td>,\n",
       " <td>January 1938 (three 78rpm singles) <a class=\"mw-redirect\" href=\"/wiki/Victor_Records\" title=\"Victor Records\">Victor Records</a></td>,\n",
       " <td>June 8, 1993 (CD)<br/>September 25, 2001 (CD) (Remastered)\n",
       " </td>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = []\n",
    "title = []\n",
    "issue = []\n",
    "reissue = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in tables:\n",
    "    labels=ent.find_all('td')\n",
    "    year.append(labels[0])\n",
    "    title.append(labels[1])\n",
    "    issue.append(labels[2])\n",
    "    reissue.append(labels[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td><i><a href=\"/wiki/Snow_White_and_the_Seven_Dwarfs_(soundtrack)\" title=\"Snow White and the Seven Dwarfs (soundtrack)\">Snow White and the Seven Dwarfs</a></i></td>,\n",
       " <td><i><a href=\"/wiki/Pinocchio_(soundtrack)\" title=\"Pinocchio (soundtrack)\">Pinocchio</a></i></td>,\n",
       " <td><span data-sort-value=\"000000001981-01-01-0000\" style=\"white-space:nowrap\">1981</span></td>,\n",
       " <td><span data-sort-value=\"000000002010-03-02-0000\" style=\"white-space:nowrap\">March 2, 2010</span>\n",
       " </td>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
