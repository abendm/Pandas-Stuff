{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Deep Learning\n",
    "## What is it and why do we hear about it so much?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Deep learning is a special area of research in Machine Learning. Deep Learning excels in certain tasks where, historically speaking, Machine Learning could was not quite so successful.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Deep learning is a special area of research in Machine Learning. Deep Learning excels in certain tasks where, historically speaking, Machine Learning could was not quite so successful.\n",
    "\n",
    "**Where do we see deep learning?**\n",
    "- Text\n",
    "- Images and Video\n",
    "- Audio\n",
    "- Trasnlation\n",
    "- Speech\n",
    "- Reinforcement Learning \n",
    "- Autonomous vehicles \n",
    "- And many more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Object Detection**\n",
    "![.](https://images.techhive.com/images/article/2017/04/screen-shot-2016-08-23-at-5.22.48-pm-100678735-orig-100720278-large.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Image captioning**\n",
    "![.](https://gigaom.com/wp-content/uploads/sites/1/2014/11/stcnrn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Neural Machine Translation**\n",
    "![.](https://devblogs.nvidia.com/wp-content/uploads/2015/07/Figure6_sample_translations1-624x282.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why are the used so often?\n",
    "\n",
    "**Because they work well!** \n",
    "\n",
    "**In particular, they work well on tasks we couldn't dream of accomplishing in the past**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspired by the brain!\n",
    "\n",
    "Neural Networks, the fundamental building blocks of **deep learning**, were inspired by the way the human brain processes information.\n",
    "\n",
    "![.](http://4.bp.blogspot.com/-Z5LfY6yoIcE/U-OFKWHoAbI/AAAAAAAAAKo/ytH6BzDLeo4/w1200-h630-p-k-no-nu/Picture-533.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The first \"Deep Learning\" device: the Perceptron\n",
    "\n",
    "researched and developed by **Frank Rosenblatt** in 1958.\n",
    "\n",
    "![.](https://pbs.twimg.com/media/DY5de__VQAABrs6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### So why didn't we hear about them for so long?\n",
    "\n",
    "**Amongst many factors, they were impracticle to use and research.**\n",
    "- Computationally too expensive\n",
    "- Limited data available and storeable \n",
    "- Optimization and convergene problems\n",
    "\n",
    "**We hear about them now thanks to advancements in a few things!**\n",
    "- Storage capabilities and LOTS of Data\n",
    "- Specialized optimization algorithms (which turned out to be exceptionally simple, ie. Chain Rule)\n",
    "- Accelerated computing (GPUs)\n",
    "- Open source software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## But what are they?\n",
    "![.](http://www.bu.edu/today/files/2012/05/t_computationalthinking.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### \"Neural Nets are just a bunch of logistic regressions\"\n",
    "![.](http://www.saedsayad.com/images/LogReg_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What happens if we restructure this model a bit?\n",
    "\n",
    "![.](https://i.stack.imgur.com/bA57S.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### If we generalize it a little, we get \n",
    "![.](https://www.cntk.ai/jup/logistic_neuron.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### This is really all Neural Networks are, but we just have a lot of them feeding into eachother!\n",
    "![.](https://i.stack.imgur.com/OH3gI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's break down the main components of Neural Networks:\n",
    "- Neurons: The input features or output values (either classes or real-values regression)\n",
    "- Activations: Functions that pass our values into to make non-linear transformations. Note that if we have multiple layers, we are passing outputs of one activation function into another activation function.\n",
    "    - Linear (not non-linear, obviously, but we use this like in our linear regressions)\n",
    "    - Sigmoid (What we use in Logistic Regression)\n",
    "    - Tanh (Very common)\n",
    "    - Relu (Becoming very popular as of late)\n",
    "- Layers: A process or function that is applied to all values passing through. \n",
    "- Loss Function: We have seen this before, and it's the same as in our machine learning algorithms!\n",
    "- Optimization procedure: The procedure by which we change our weights! Each node has a set of weights!\n",
    "    - Backpropogation: The chain-rule! This is the work horse algorithm of Neural Networks\n",
    "    - Stochastic Gradient Descent: The most common procedure for optimizing these models today.\n",
    "    - Batch: A subset of your training set that we compute over our loss funtion.\n",
    "    - Epoch: A single pass of all of your training set through the data. All your batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some of our activation funtions:\n",
    "![.](https://cdn-images-1.medium.com/max/800/1*p_hyqAtyI8pbt2kEl6siOQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training our models:\n",
    "![.](https://image.slidesharecdn.com/bayesianoptimization-160901100248/95/bayesian-optimization-applied-to-neural-networks-3-638.jpg?cb=1472725122)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are many different flavors of NNs\n",
    "\n",
    "- Feed Forward Neural Networks (FNNs)\n",
    "- Convolutional Neural Networks (CNNs) for image and video processing\n",
    "- Recurrent Neural Networks (RNNs) for learning sequences in video, text, and time-series\n",
    "- Generative Adversarial Networks (GANs) for gnerating new data based on known data, of any kind!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today, we will focus on one flavor: CNNs for images\n",
    "\n",
    "![.](https://adeshpande3.github.io/assets/Cover.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images as pixels\n",
    "\n",
    "![.](https://adeshpande3.github.io/assets/Filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we zoom out, it's a mouse!\n",
    "\n",
    "![.](https://adeshpande3.github.io/assets/OriginalAndFilter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The key to CNNs is the \"Convolutional\" filters, or kernel _weights_\n",
    "\n",
    "![.](https://adeshpande3.github.io/assets/SecondMultiplication.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convultions are done over the **entire** image\n",
    "\n",
    "![.](https://cdn-images-1.medium.com/max/800/1*_34EtrgYk6cQxlJ2br51HQ.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then take the outputs of those \"volumes\" and we process them again in a \"pool\" to get the _most relevant features_\n",
    "\n",
    "![.](https://cdn-images-1.medium.com/max/800/1*S86gKd43MIYquHIeR9m8JQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look again and see them all together\n",
    "\n",
    "![.](https://adeshpande3.github.io/assets/Cover.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This process \"learns\" some amazing things\n",
    "\n",
    "![.](https://cdn-images-1.medium.com/max/800/1*2SWb6CmxzbPZijmevFbe-g.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's train our own! \n",
    "\n",
    "I put together our own CNN that is learning the [CIFAR 10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset of images (you will see it soon). \n",
    "\n",
    "I did this in a Google Colab notebook so that we have access to a GPU! \n",
    "\n",
    "**Please do not run this notebook. Make your own copy and then try it yourself!**\n",
    "\n",
    "[Notebook](https://drive.google.com/file/d/17UhyQh1hfSOGHuvXoRAbv6OI7cUa2Gk5/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
