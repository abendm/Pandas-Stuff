{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Donor's Choose\n",
    "\n",
    "1. What is the primary metric you care about in this task?  Be sure to clearly state the question about why this is the case.\n",
    "1. Is the column `teacher_number_of_previously_posted_projects` a good predictor for the approval of the project? Use both a `KNearestNeighbors` and `LogisticRegression` model. Which model performs better?  Can you select the best parameters for each?  The best penalty for `LogisticRegression`?  Form a pipeline that includes a scaling transformation?  Compare this to a `DummyClassifier`?\n",
    "2. What are the top 8 states in terms of raw number approved? The lowest?  Show me with a nice barplot.\n",
    "3. Are these states different from the number of proportion of applications approved by state?  Show me.\n",
    "4. Does your model improve with the inclusion of the `teacher_prefix` column in a `LogisticRegression` model?\n",
    "5. What is your best parameter for the training set with these inputs?\n",
    "6. Construct a feature that is simply `STEM`, which is 1 if a scientific discipline is a part of the `subject_subcategory` column, or 0 if not.  Did your model improve?\n",
    "7. What if you include the `project_grade_category` column?  Is your model improved?\n",
    "8. What if your client only cares about what's happening in New York.  Is there a difference in the performance of a `LogisticRegression` model? `KNearestNeighbors`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv', index_col = 'id')\n",
    "test = pd.read_csv('data/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 182080 entries, p036502 to p190772\n",
      "Data columns (total 15 columns):\n",
      "teacher_id                                      182080 non-null object\n",
      "teacher_prefix                                  182076 non-null object\n",
      "school_state                                    182080 non-null object\n",
      "project_submitted_datetime                      182080 non-null object\n",
      "project_grade_category                          182080 non-null object\n",
      "project_subject_categories                      182080 non-null object\n",
      "project_subject_subcategories                   182080 non-null object\n",
      "project_title                                   182080 non-null object\n",
      "project_essay_1                                 182080 non-null object\n",
      "project_essay_2                                 182080 non-null object\n",
      "project_essay_3                                 6374 non-null object\n",
      "project_essay_4                                 6374 non-null object\n",
      "project_resource_summary                        182080 non-null object\n",
      "teacher_number_of_previously_posted_projects    182080 non-null int64\n",
      "project_is_approved                             182080 non-null int64\n",
      "dtypes: int64(2), object(13)\n",
      "memory usage: 22.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.teacher_number_of_previously_posted_projects.values.reshape(-1,1)\n",
    "y = train.project_is_approved\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(X_test)\n",
    "clf_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7414543057996485"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum = DummyClassifier()\n",
    "dum.fit(X_train, y_train)\n",
    "dum.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for knn is 0.8444200351493849\n",
      "score for Logistic Regressions is 0.8449253075571177\n",
      "score for Dummy is 0.7391695957820739\n"
     ]
    }
   ],
   "source": [
    "knn_rmse = np.sqrt(mean_squared_error(knn_pred, y_test))\n",
    "clf_rmse = np.sqrt(mean_squared_error(clf_pred, y_test))\n",
    "print(\"score for knn is\", knn.score(X_test, y_test))\n",
    "print(\"score for Logistic Regressions is\", clf.score(X_test, y_test))\n",
    "print(\"score for Dummy is\", dum.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without optimizing the classifiers, it looks like the dummy does better than the other two.  I'm moving onto task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 182080 entries, p036502 to p190772\n",
      "Data columns (total 15 columns):\n",
      "teacher_id                                      182080 non-null object\n",
      "teacher_prefix                                  182076 non-null object\n",
      "school_state                                    182080 non-null object\n",
      "project_submitted_datetime                      182080 non-null object\n",
      "project_grade_category                          182080 non-null object\n",
      "project_subject_categories                      182080 non-null object\n",
      "project_subject_subcategories                   182080 non-null object\n",
      "project_title                                   182080 non-null object\n",
      "project_essay_1                                 182080 non-null object\n",
      "project_essay_2                                 182080 non-null object\n",
      "project_essay_3                                 6374 non-null object\n",
      "project_essay_4                                 6374 non-null object\n",
      "project_resource_summary                        182080 non-null object\n",
      "teacher_number_of_previously_posted_projects    182080 non-null int64\n",
      "project_is_approved                             182080 non-null int64\n",
      "dtypes: int64(2), object(13)\n",
      "memory usage: 27.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_states = train.groupby(train.school_state)\n",
    "approved_sum = best_states.project_is_approved.sum().sort_values(ascending=False)\n",
    "approved_sum = approved_sum.nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I can't get the barplot to work quickly, so skipping for now.  The below is adding the teacher prefix as a feature for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mrs.       95405\n",
       "Ms.        65066\n",
       "Mr.        17667\n",
       "Teacher     3912\n",
       "Dr.           26\n",
       "Name: teacher_prefix, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.teacher_prefix.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "teacher_prefix\n",
       "Dr.        0.807692\n",
       "Mr.        0.842022\n",
       "Mrs.       0.854085\n",
       "Ms.        0.843052\n",
       "Teacher    0.794223\n",
       "Name: project_is_approved, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('teacher_prefix')['project_is_approved'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = train[['teacher_prefix', 'teacher_number_of_previously_posted_projects']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.get_dummies(p2, drop_first=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>teacher_prefix_Dr.</th>\n",
       "      <th>teacher_prefix_Mr.</th>\n",
       "      <th>teacher_prefix_Mrs.</th>\n",
       "      <th>teacher_prefix_Ms.</th>\n",
       "      <th>teacher_prefix_Teacher</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p036502</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p039565</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p233823</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p185307</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p013780</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         teacher_number_of_previously_posted_projects  teacher_prefix_Dr.  \\\n",
       "id                                                                          \n",
       "p036502                                            26                   0   \n",
       "p039565                                             1                   0   \n",
       "p233823                                             5                   0   \n",
       "p185307                                            16                   0   \n",
       "p013780                                            42                   0   \n",
       "\n",
       "         teacher_prefix_Mr.  teacher_prefix_Mrs.  teacher_prefix_Ms.  \\\n",
       "id                                                                     \n",
       "p036502                   0                    0                   1   \n",
       "p039565                   0                    1                   0   \n",
       "p233823                   0                    0                   1   \n",
       "p185307                   1                    0                   0   \n",
       "p013780                   1                    0                   0   \n",
       "\n",
       "         teacher_prefix_Teacher  \n",
       "id                               \n",
       "p036502                       0  \n",
       "p039565                       0  \n",
       "p233823                       0  \n",
       "p185307                       0  \n",
       "p013780                       0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Now that the prefix has been dummied, the next step would be to re-do the above where we split, trained, fit, and scored the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y_train, y_test = train_test_split(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X2_train, y_train)\n",
    "knn.fit(X2_train, y_train)\n",
    "dum.fit(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490553602811951\n",
      "0.7838532513181019\n",
      "0.7417398945518453\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X2_test, y_test))\n",
    "print(knn.score(X2_test, y_test))\n",
    "print(dum.score(X2_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a STEM feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Literacy & Language                           39257\n",
       "Math & Science                                28555\n",
       "Literacy & Language, Math & Science           24499\n",
       "Health & Sports                               16951\n",
       "Music & The Arts                               8527\n",
       "Special Needs                                  7065\n",
       "Literacy & Language, Special Needs             6685\n",
       "Applied Learning                               6310\n",
       "Math & Science, Literacy & Language            3843\n",
       "Applied Learning, Literacy & Language          3725\n",
       "History & Civics                               3065\n",
       "Math & Science, Special Needs                  3010\n",
       "Literacy & Language, Music & The Arts          2878\n",
       "Math & Science, Music & The Arts               2761\n",
       "Applied Learning, Special Needs                2481\n",
       "Health & Sports, Special Needs                 2368\n",
       "History & Civics, Literacy & Language          2288\n",
       "Warmth, Care & Hunger                          2191\n",
       "Math & Science, Applied Learning               2071\n",
       "Applied Learning, Math & Science               1711\n",
       "Literacy & Language, History & Civics          1315\n",
       "Health & Sports, Literacy & Language           1308\n",
       "Applied Learning, Music & The Arts             1241\n",
       "Math & Science, History & Civics               1087\n",
       "Literacy & Language, Applied Learning          1038\n",
       "Applied Learning, Health & Sports              1018\n",
       "Math & Science, Health & Sports                 697\n",
       "History & Civics, Music & The Arts              544\n",
       "History & Civics, Math & Science                525\n",
       "Special Needs, Music & The Arts                 521\n",
       "Health & Sports, Math & Science                 470\n",
       "History & Civics, Special Needs                 417\n",
       "Applied Learning, History & Civics              303\n",
       "Health & Sports, Applied Learning               297\n",
       "Health & Sports, Music & The Arts               262\n",
       "Music & The Arts, Special Needs                 235\n",
       "Literacy & Language, Health & Sports            127\n",
       "Health & Sports, History & Civics                67\n",
       "History & Civics, Applied Learning               65\n",
       "Special Needs, Health & Sports                   64\n",
       "Special Needs, Warmth, Care & Hunger             35\n",
       "Music & The Arts, Health & Sports                32\n",
       "Health & Sports, Warmth, Care & Hunger           31\n",
       "Music & The Arts, History & Civics               29\n",
       "Literacy & Language, Warmth, Care & Hunger       25\n",
       "Applied Learning, Warmth, Care & Hunger          22\n",
       "Music & The Arts, Applied Learning               21\n",
       "History & Civics, Health & Sports                20\n",
       "Math & Science, Warmth, Care & Hunger            19\n",
       "Music & The Arts, Warmth, Care & Hunger           3\n",
       "History & Civics, Warmth, Care & Hunger           1\n",
       "Name: project_subject_categories, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.project_subject_categories.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above shows the the string \"Math & Science\" is what distinguishes a STEM category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['STEM'] = train.project_subject_categories.str.contains('Math & Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = train[['teacher_prefix', 'teacher_number_of_previously_posted_projects', 'STEM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.get_dummies(p3, drop_first=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>STEM</th>\n",
       "      <th>teacher_prefix_Mr.</th>\n",
       "      <th>teacher_prefix_Mrs.</th>\n",
       "      <th>teacher_prefix_Ms.</th>\n",
       "      <th>teacher_prefix_Teacher</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p036502</th>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p039565</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p233823</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p185307</th>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p013780</th>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         teacher_number_of_previously_posted_projects   STEM  \\\n",
       "id                                                             \n",
       "p036502                                            26  False   \n",
       "p039565                                             1  False   \n",
       "p233823                                             5   True   \n",
       "p185307                                            16  False   \n",
       "p013780                                            42  False   \n",
       "\n",
       "         teacher_prefix_Mr.  teacher_prefix_Mrs.  teacher_prefix_Ms.  \\\n",
       "id                                                                     \n",
       "p036502                   0                    0                   1   \n",
       "p039565                   0                    1                   0   \n",
       "p233823                   0                    0                   1   \n",
       "p185307                   1                    0                   0   \n",
       "p013780                   1                    0                   0   \n",
       "\n",
       "         teacher_prefix_Teacher  \n",
       "id                               \n",
       "p036502                       0  \n",
       "p039565                       0  \n",
       "p233823                       0  \n",
       "p185307                       0  \n",
       "p013780                       0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Now that the prefix has been dummied, the next step would be to re-do the above where we split, trained, fit, and scored the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train, X3_test, y_train, y_test = train_test_split(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X3_train, y_train)\n",
    "knn.fit(X3_train, y_train)\n",
    "dum.fit(X3_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8473637961335677\n",
      "0.8407513181019333\n",
      "0.7449033391915642\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X3_test, y_test))\n",
    "print(knn.score(X3_test, y_test))\n",
    "print(dum.score(X3_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
