{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Refresher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"System of the World. By Isaac Newton\", \"   Snow Crash  .  By Neal Stephenson \",\n",
    "       \" AFROFUTURISM. by     Ytasha L. Womack \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_whitespace = [string.strip() for string in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['System of the World. By Isaac Newton',\n",
       " 'Snow Crash  .  By Neal Stephenson',\n",
       " 'AFROFUTURISM. by     Ytasha L. Womack']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['System of the World. By Isaac Newton',\n",
       " 'Snow Crash  .  By Neal Stephenson',\n",
       " 'AFROFUTURISM. by     Ytasha L. Womack']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip_whitespace2 = [string.strip() for string in strip_whitespace]\n",
    "strip_whitespace2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_periods = [string.replace(\".\",\"\") for string in strip_whitespace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['System of the World By Isaac Newton',\n",
       " 'Snow Crash    By Neal Stephenson',\n",
       " 'AFROFUTURISM by     Ytasha L Womack']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = [string.upper() for string in strip_whitespace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SYSTEM OF THE WORLD. BY ISAAC NEWTON',\n",
       " 'SNOW CRASH  .  BY NEAL STEPHENSON',\n",
       " 'AFROFUTURISM. BY     YTASHA L. WOMACK']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [re.sub(r\"[a-zA-Z]\", \"X\", string) for string in strip_whitespace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XXXXXX XX XXX XXXXX. XX XXXXX XXXXXX',\n",
       " 'XXXX XXXXX  .  XX XXXX XXXXXXXXXX',\n",
       " 'XXXXXXXXXXXX. XX     XXXXXX X. XXXXXX']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REGEX TUTORIAL**\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2015/06/regular-expression-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.analyticsvidhya.com/blog/2015/06/regular-expression-python/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lar Expres'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.text[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2 class=\"site-outline\">Learn everything about Analytics</h2>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/NYCMath/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgraph = soup.find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokes = word_tokenize(pgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'last',\n",
       " 'few',\n",
       " 'years',\n",
       " ',',\n",
       " 'there',\n",
       " 'has',\n",
       " 'been',\n",
       " 'a',\n",
       " 'dramatic',\n",
       " 'shift',\n",
       " 'in',\n",
       " 'usage',\n",
       " 'of',\n",
       " 'general',\n",
       " 'purpose',\n",
       " 'programming',\n",
       " 'languages',\n",
       " 'for',\n",
       " 'data',\n",
       " 'science',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'This',\n",
       " 'was',\n",
       " 'not',\n",
       " 'always',\n",
       " 'the',\n",
       " 'case',\n",
       " '–',\n",
       " 'a',\n",
       " 'decade',\n",
       " 'back',\n",
       " 'this',\n",
       " 'thought',\n",
       " 'would',\n",
       " 'have',\n",
       " 'met',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'skeptic',\n",
       " 'eyes',\n",
       " '!']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy = ['.', ',', '!', '-', '?','*', '–']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In\n",
      "last\n",
      "few\n",
      "years\n",
      "there\n",
      "has\n",
      "been\n",
      "a\n",
      "dramatic\n",
      "shift\n",
      "in\n",
      "usage\n",
      "of\n",
      "general\n",
      "purpose\n",
      "programming\n",
      "languages\n",
      "for\n",
      "data\n",
      "science\n",
      "and\n",
      "machine\n",
      "learning\n",
      "This\n",
      "was\n",
      "not\n",
      "always\n",
      "the\n",
      "case\n",
      "a\n",
      "decade\n",
      "back\n",
      "this\n",
      "thought\n",
      "would\n",
      "have\n",
      "met\n",
      "a\n",
      "lot\n",
      "of\n",
      "skeptic\n",
      "eyes\n"
     ]
    }
   ],
   "source": [
    "for word in tokes:\n",
    "    if word not in sy:\n",
    "        print(word)\n",
    "    else:\n",
    "        _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In last few years, there has been a dramatic shift in usage of general purpose programming languages for data science and machine learning.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(pgraph)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'last',\n",
       " 'years',\n",
       " ',',\n",
       " 'dramatic',\n",
       " 'shift',\n",
       " 'usage',\n",
       " 'general',\n",
       " 'purpose',\n",
       " 'programming',\n",
       " 'languages',\n",
       " 'data',\n",
       " 'science',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'This',\n",
       " 'always',\n",
       " 'case',\n",
       " '–',\n",
       " 'decade',\n",
       " 'back',\n",
       " 'thought',\n",
       " 'would',\n",
       " 'met',\n",
       " 'lot',\n",
       " 'skeptic',\n",
       " 'eyes',\n",
       " '!']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in tokes if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'last',\n",
       " 'few',\n",
       " 'year',\n",
       " ',',\n",
       " 'there',\n",
       " 'ha',\n",
       " 'been',\n",
       " 'a',\n",
       " 'dramat',\n",
       " 'shift',\n",
       " 'in',\n",
       " 'usag',\n",
       " 'of',\n",
       " 'gener',\n",
       " 'purpos',\n",
       " 'program',\n",
       " 'languag',\n",
       " 'for',\n",
       " 'data',\n",
       " 'scienc',\n",
       " 'and',\n",
       " 'machin',\n",
       " 'learn',\n",
       " '.',\n",
       " 'thi',\n",
       " 'wa',\n",
       " 'not',\n",
       " 'alway',\n",
       " 'the',\n",
       " 'case',\n",
       " '–',\n",
       " 'a',\n",
       " 'decad',\n",
       " 'back',\n",
       " 'thi',\n",
       " 'thought',\n",
       " 'would',\n",
       " 'have',\n",
       " 'met',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'skeptic',\n",
       " 'eye',\n",
       " '!']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(word) for word in tokes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tagged = pos_tag(tokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'IN'),\n",
       " ('last', 'JJ'),\n",
       " ('few', 'JJ'),\n",
       " ('years', 'NNS'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('dramatic', 'JJ'),\n",
       " ('shift', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('usage', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('general', 'JJ'),\n",
       " ('purpose', 'NN'),\n",
       " ('programming', 'NN'),\n",
       " ('languages', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DT'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('always', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('case', 'NN'),\n",
       " ('–', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('decade', 'NN'),\n",
       " ('back', 'RB'),\n",
       " ('this', 'DT'),\n",
       " ('thought', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('met', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('lot', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('skeptic', 'JJ'),\n",
       " ('eyes', 'NNS'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['years',\n",
       " 'shift',\n",
       " 'usage',\n",
       " 'purpose',\n",
       " 'programming',\n",
       " 'languages',\n",
       " 'data',\n",
       " 'science',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'case',\n",
       " 'decade',\n",
       " 'thought',\n",
       " 'lot',\n",
       " 'eyes']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word, tag in text_tagged if tag in ['NN', 'NNS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\"we are more worried about what we can lose than what we feel\",\n",
    "         \"it's really cool to say I hate you. But it's not cool to say I love you. Love has a stigma\",\n",
    "         \"Instead of doing what you feel you just do what other people think you should do\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tweets = []\n",
    "for tweet in tweets:\n",
    "    tweet_tag = pos_tag(word_tokenize(tweet))\n",
    "    tagged_tweets.append([tag for word, tag in tweet_tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RB', 'IN', 'VBG', 'WP', 'PRP']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tweets[2][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_multi = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_multi.fit_transform(tagged_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.', 'CC', 'DT', 'IN', 'JJ', 'MD', 'NN', 'NNS', 'PRP', 'RB', 'RBR',\n",
       "       'TO', 'VB', 'VBG', 'VBP', 'VBZ', 'WP'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_multi.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = np.array(['I like Cardi B. ', 'Tribeca is a strange place.', ' Germany is where they make volkswagen cars.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = count.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardi',\n",
       " 'cars',\n",
       " 'germany',\n",
       " 'is',\n",
       " 'like',\n",
       " 'make',\n",
       " 'place',\n",
       " 'strange',\n",
       " 'they',\n",
       " 'tribeca',\n",
       " 'volkswagen',\n",
       " 'where']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardi',\n",
       " 'cars',\n",
       " 'germany',\n",
       " 'is',\n",
       " 'like',\n",
       " 'make',\n",
       " 'place',\n",
       " 'strange',\n",
       " 'they',\n",
       " 'tribeca',\n",
       " 'volkswagen',\n",
       " 'where']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_2gram = CountVectorizer(ngram_range = (1, 2), stop_words=\"english\", \n",
    "                             vocabulary=['cardi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = count_2gram.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x12 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.        , 0.        , 0.        , 0.70710678,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.40204024, 0.        ,\n",
       "        0.        , 0.52863461, 0.52863461, 0.        , 0.52863461,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.38988801, 0.38988801, 0.29651988, 0.        ,\n",
       "        0.38988801, 0.        , 0.        , 0.38988801, 0.        ,\n",
       "        0.38988801, 0.38988801]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cardi': 0,\n",
       " 'cars': 1,\n",
       " 'germany': 2,\n",
       " 'is': 3,\n",
       " 'like': 4,\n",
       " 'make': 5,\n",
       " 'place': 6,\n",
       " 'strange': 7,\n",
       " 'they': 8,\n",
       " 'tribeca': 9,\n",
       " 'volkswagen': 10,\n",
       " 'where': 11}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
